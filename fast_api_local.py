
import uvicorn
import os
import io
import threading
import requests
import time
from PIL import Image
from libary_local import *
from model_local import *
from tokenizers_local import *
from load_model_local import *

# ‚úÖ Kh·ªüi t·∫°o FastAPI
app = FastAPI()

# ‚úÖ Trang ch√≠nh (upload ·∫£nh)
@app.get("/", response_class=HTMLResponse)
async def homepage():
    with open("form_local.html", "r") as f:
        return f.read()

# ‚úÖ API d·ª± ƒëo√°n caption ·∫£nh
@app.post("/predict")
async def predict(file: UploadFile = File(...), lang: str = Form("en")):
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        image = image_transform(image).to(device)
        caption = model.predict_caption(image, tokenizers[lang_id[lang]], lang_id=lang_id[lang], mode='greedy')
        return {"caption": caption, "language": lang}
    except Exception as e:
        return {"error": str(e)}

# ‚úÖ L·∫•y PORT t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (Render t·ª± ƒë·ªông set)
PORT = int(os.environ.get("PORT", 8000))
SERVER_URL = os.environ.get("PUBLIC_URL", f"https://fastapi-app.onrender.com")

# ‚úÖ H√†m g·ª≠i request gi·ªØ server lu√¥n ho·∫°t ƒë·ªông (tr√°nh auto sleep)
def keep_awake():
    while True:
        try:
            response = requests.get(SERVER_URL)
            print(f"üîÑ Ping {SERVER_URL}: {response.status_code}")
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói gi·ªØ server online: {e}")
        time.sleep(600)  # Ping m·ªói 10 ph√∫t

# ‚úÖ Ch·∫°y lu·ªìng gi·ªØ server kh√¥ng b·ªã ng·ªß
keep_awake_thread = threading.Thread(target=keep_awake)
keep_awake_thread.daemon = True
keep_awake_thread.start()

# ‚úÖ Ch·∫°y server tr√™n Render
if __name__ == "__main__":
    print(f"üöÄ Server ch·∫°y t·∫°i {SERVER_URL}")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
